{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce1b2fd",
   "metadata": {},
   "source": [
    "## install boto3 for creating the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "185a6476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-sql\n",
      "  Downloading ipython_sql-0.4.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython-sql) (1.4.19)\n",
      "Requirement already satisfied: six in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython-sql) (1.16.0)\n",
      "Collecting sqlparse\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "     -------------------------------------- 42.8/42.8 kB 692.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: ipython>=1.0 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython-sql) (7.31.1)\n",
      "Collecting prettytable<1\n",
      "  Downloading prettytable-0.7.2.zip (28 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (52.0.0.post20210125)\n",
      "Requirement already satisfied: colorama in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.4.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (3.0.17)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (5.0.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (2.9.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\omar\\anaconda3\\lib\\site-packages (from ipython>=1.0->ipython-sql) (5.0.9)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\omar\\anaconda3\\lib\\site-packages (from sqlalchemy>=0.6.7->ipython-sql) (3.10.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from sqlalchemy>=0.6.7->ipython-sql) (1.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\omar\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\omar\\anaconda3\\lib\\site-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (3.5.0)\n",
      "Building wheels for collected packages: prettytable\n",
      "  Building wheel for prettytable (setup.py): started\n",
      "  Building wheel for prettytable (setup.py): finished with status 'done'\n",
      "  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13699 sha256=0b59040af854ad90df634388ca7621a435ae2160ab301af4f7f6fc8c09063195\n",
      "  Stored in directory: c:\\users\\omar\\appdata\\local\\pip\\cache\\wheels\\b2\\7f\\f6\\f180315b584f00445045ff1699b550fa895d09471337ce21c6\n",
      "Successfully built prettytable\n",
      "Installing collected packages: prettytable, sqlparse, ipython-sql\n",
      "Successfully installed ipython-sql-0.4.1 prettytable-0.7.2 sqlparse-0.4.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install boto3\n",
    "# !pip install ipython-sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3107f2c",
   "metadata": {},
   "source": [
    "# If you already created a cluster then go to step 2 directly with the new credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d250ce",
   "metadata": {},
   "source": [
    "# Step 1 Create a Cluster\n",
    "\n",
    "### Import the lib important for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16d9cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485b08a",
   "metadata": {},
   "source": [
    "## Load Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f5d2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "# AWS\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "REGION_NAME            = config.get('AWS','REGION_NAME')\n",
    "\n",
    "# DWH\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "# S3\n",
    "LOG_DATA               = config.get('S3', 'LOG_DATA')\n",
    "LOG_JSONPATH           = config.get('S3', 'LOG_JSONPATH')\n",
    "SONG_DATA              = config.get('S3', 'SONG_DATA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d6c3aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param       Value\n",
       "0  DWH_CLUSTER_TYPE        multi-node\n",
       "1  DWH_NUM_NODES           2         \n",
       "2  DWH_NODE_TYPE           dc2.large \n",
       "3  DWH_CLUSTER_IDENTIFIER  dwhCluster\n",
       "4  DWH_DB                  dwh       \n",
       "5  DWH_DB_USER             dwhuser   \n",
       "6  DWH_DB_PASSWORD         Passw0rd  \n",
       "7  DWH_PORT                5439      \n",
       "8  DWH_IAM_ROLE_NAME       dwhRole   "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the credentials\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af329e93",
   "metadata": {},
   "source": [
    "## Create clients for IAM, EC2, S3 and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad16b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=REGION_NAME,\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=REGION_NAME,\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name=REGION_NAME\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name= REGION_NAME,\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff55958",
   "metadata": {},
   "source": [
    "## Check out the sample data sources on S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "202c1e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of logs: 31\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of JSON files in the folder 's3://udacity-dend/log_data'\n",
    "count_logs = sum(1 for _ in s3.Bucket('udacity-dend').objects.filter(Prefix='log_data'))\n",
    "\n",
    "print(\"Total number of logs: \" + str(count_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc812602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of songs: 31\n"
     ]
    }
   ],
   "source": [
    "count_songs = sum(1 for _ in s3.Bucket('udacity-dend').objects.filter(Prefix='song_data'))\n",
    "\n",
    "print(\"Total number of songs: \" + str(count_logs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aee99d",
   "metadata": {},
   "source": [
    "## Create a new IAM user\n",
    "Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0470e687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::701898129859:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931e6c7",
   "metadata": {},
   "source": [
    "## Create Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d904b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef117372",
   "metadata": {},
   "source": [
    "## 2.1 *Describe* the cluster to see its status\n",
    "- run this block several times until the cluster status becomes `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7a9fc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0d153cb688ae4965e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-0d153cb688ae4965e                                                                  \n",
       "7  2                                                                                      "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386268df",
   "metadata": {},
   "source": [
    "## Take note of the cluster endpoint and role ARN\n",
    "DO NOT RUN THIS unless the cluster status becomes \"Available\". Make sure you are checking your Amazon Redshift cluster in the **us-west-2** region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bce437dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift enpoint: 'dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com'\n"
     ]
    }
   ],
   "source": [
    "# Get the Redshift endpoint and the ARN role\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "# Show the endpoint\n",
    "print(\"Redshift enpoint: '\" + DWH_ENDPOINT + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9adf38",
   "metadata": {},
   "source": [
    "Is important to store this endpoint URL in the file dwh.cfg in the parameters [DWH].DWH_ENDPOINT and [CLUSTER].HOST.\n",
    "\n",
    "The value of DWH_ROLE_ARN it also needed to be saved in the file dwh.cfg in the parameter [IAM_ROLE].ARN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df260ada",
   "metadata": {},
   "source": [
    "## Open an incoming TCP port to access the cluster ednpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85bb99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-0dae4ac3a1a83e065')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37755e",
   "metadata": {},
   "source": [
    "# Step 2 Make sure you can connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fd6bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dac26a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e8e4e",
   "metadata": {},
   "source": [
    "# STEP 3 Create Schema and Insert into Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "29a2c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database\n",
      "Successfuly connected to the database\n",
      "Dropping tables if exists\n",
      "Creating tables if not exists\n",
      "Completed the dropping and creation of the schema\n"
     ]
    }
   ],
   "source": [
    "# Create the tables in the database\n",
    "%run create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15effa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database\n",
      "Successfuly connected to the database\n",
      "Loading staging_tables\n",
      "Inserting to tables\n",
      "Completed the loading and insertion of the data\n"
     ]
    }
   ],
   "source": [
    "# Run the ETL script to upload data to the Redshift cluster\n",
    "!python etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c944c16",
   "metadata": {},
   "source": [
    "# STEP 4 Test and Analyize the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c2ad106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Redshift cluster\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(DWH_ENDPOINT,DWH_DB,DWH_DB_USER,DWH_DB_PASSWORD,DWH_PORT))\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3d1b84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n\n",
       "0  333"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of row in the table songplays\n",
    "pd.read_sql_query(\"\"\"SELECT COUNT(*) AS N FROM songplays\"\"\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89d7687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.OperationalError) SSL SYSCALL error: EOF detected\n",
      "\n",
      "[SQL: SELECT * FROM users LIMIT 5;]\n",
      "(Background on this error at: http://sqlalche.me/e/14/e3q8)\n"
     ]
    }
   ],
   "source": [
    "%sql SELECT * FROM users LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b5059ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n\n",
       "0  104"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"\"\"SELECT COUNT(*) AS N FROM users\"\"\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6902d346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>song_id</th>\n",
       "        <th>title</th>\n",
       "        <th>artist_id</th>\n",
       "        <th>year</th>\n",
       "        <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SOAACFC12A8C140567</td>\n",
       "        <td>Supernatural Pt. II</td>\n",
       "        <td>ARNHTE41187B99289A</td>\n",
       "        <td>0</td>\n",
       "        <td>343.09179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SOAACTC12AB0186A20</td>\n",
       "        <td>Christmas Is Coming Soon</td>\n",
       "        <td>ARXWFZ21187FB43A0B</td>\n",
       "        <td>2008</td>\n",
       "        <td>180.76689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SOAADJH12AB018BD30</td>\n",
       "        <td>Black Light (Album Version)</td>\n",
       "        <td>AR3FKJ61187B990357</td>\n",
       "        <td>1975</td>\n",
       "        <td>385.90649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SOAAEHR12A6D4FB060</td>\n",
       "        <td>Slaves &amp; Bulldozers</td>\n",
       "        <td>AR5N8VN1187FB37A4E</td>\n",
       "        <td>1991</td>\n",
       "        <td>415.81669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SOAAFUV12AB018831D</td>\n",
       "        <td>Where Do The Children Play? (LP Version)</td>\n",
       "        <td>AR5ZGC11187FB417A3</td>\n",
       "        <td>0</td>\n",
       "        <td>216.05832</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('SOAACFC12A8C140567', 'Supernatural Pt. II', 'ARNHTE41187B99289A', 0, 343.09179),\n",
       " ('SOAACTC12AB0186A20', 'Christmas Is Coming Soon', 'ARXWFZ21187FB43A0B', 2008, 180.76689),\n",
       " ('SOAADJH12AB018BD30', 'Black Light (Album Version)', 'AR3FKJ61187B990357', 1975, 385.90649),\n",
       " ('SOAAEHR12A6D4FB060', 'Slaves & Bulldozers', 'AR5N8VN1187FB37A4E', 1991, 415.81669),\n",
       " ('SOAAFUV12AB018831D', 'Where Do The Children Play? (LP Version)', 'AR5ZGC11187FB417A3', 0, 216.05832)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM songs LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65b20d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n\n",
       "0  14896"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"\"\"SELECT COUNT(*) AS N FROM songs\"\"\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f6df722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>artist_id</th>\n",
       "        <th>name</th>\n",
       "        <th>location</th>\n",
       "        <th>latitude</th>\n",
       "        <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AR00MQ31187B9ACD8F</td>\n",
       "        <td>Chris Carrier</td>\n",
       "        <td></td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AR01S3D1187FB50A53</td>\n",
       "        <td>Charlie Parr</td>\n",
       "        <td>Minnesota</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AR01WHF1187B9B53B8</td>\n",
       "        <td>Lullatone</td>\n",
       "        <td>Nagoya, Japan</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AR039B11187B9B30D0</td>\n",
       "        <td>John Williams</td>\n",
       "        <td>NEW YORK, New York</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AR040QX1187FB4CFE1</td>\n",
       "        <td>Alexisonfire</td>\n",
       "        <td>St. Catharines, ON, Canada</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('AR00MQ31187B9ACD8F', 'Chris Carrier', '', None, None),\n",
       " ('AR01S3D1187FB50A53', 'Charlie Parr', 'Minnesota', None, None),\n",
       " ('AR01WHF1187B9B53B8', 'Lullatone', 'Nagoya, Japan', None, None),\n",
       " ('AR039B11187B9B30D0', 'John Williams', 'NEW YORK, New York', None, None),\n",
       " ('AR040QX1187FB4CFE1', 'Alexisonfire', 'St. Catharines, ON, Canada', None, None)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM artists LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae9f0236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n\n",
       "0  10025"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"\"\"SELECT COUNT(*) AS N FROM artists\"\"\", con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5ce52b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>start_time</th>\n",
       "        <th>hour</th>\n",
       "        <th>day</th>\n",
       "        <th>week</th>\n",
       "        <th>month</th>\n",
       "        <th>year</th>\n",
       "        <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-11-02 16:35:00</td>\n",
       "        <td>16</td>\n",
       "        <td>2</td>\n",
       "        <td>44</td>\n",
       "        <td>11</td>\n",
       "        <td>2018</td>\n",
       "        <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-11-03 01:12:26</td>\n",
       "        <td>1</td>\n",
       "        <td>3</td>\n",
       "        <td>44</td>\n",
       "        <td>11</td>\n",
       "        <td>2018</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-11-03 17:59:01</td>\n",
       "        <td>17</td>\n",
       "        <td>3</td>\n",
       "        <td>44</td>\n",
       "        <td>11</td>\n",
       "        <td>2018</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-11-03 18:19:10</td>\n",
       "        <td>18</td>\n",
       "        <td>3</td>\n",
       "        <td>44</td>\n",
       "        <td>11</td>\n",
       "        <td>2018</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>2018-11-03 19:33:39</td>\n",
       "        <td>19</td>\n",
       "        <td>3</td>\n",
       "        <td>44</td>\n",
       "        <td>11</td>\n",
       "        <td>2018</td>\n",
       "        <td>6</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2018, 11, 2, 16, 35), 16, 2, 44, 11, 2018, '5'),\n",
       " (datetime.datetime(2018, 11, 3, 1, 12, 26), 1, 3, 44, 11, 2018, '6'),\n",
       " (datetime.datetime(2018, 11, 3, 17, 59, 1), 17, 3, 44, 11, 2018, '6'),\n",
       " (datetime.datetime(2018, 11, 3, 18, 19, 10), 18, 3, 44, 11, 2018, '6'),\n",
       " (datetime.datetime(2018, 11, 3, 19, 33, 39), 19, 3, 44, 11, 2018, '6')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM time LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77919974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n\n",
       "0  319"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"\"\"SELECT COUNT(*) AS N FROM time\"\"\", con = conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c91f9",
   "metadata": {},
   "source": [
    "# Step 5 Clean up your resources\n",
    "DO NOT RUN THIS UNLESS YOU ARE SURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "60c53a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2023, 2, 3, 12, 16, 53, 884000, tzinfo=tzutc()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-04c8836faeb8bb621',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-0d153cb688ae4965e',\n",
       "  'AvailabilityZone': 'us-west-2d',\n",
       "  'PreferredMaintenanceWindow': 'sat:07:30-sat:08:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 2,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::701898129859:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2023, 2, 4, 7, 30, tzinfo=tzutc()),\n",
       "  'TotalStorageCapacityInMegaBytes': 800000,\n",
       "  'AquaConfiguration': {'AquaStatus': 'disabled',\n",
       "   'AquaConfigurationStatus': 'auto'}},\n",
       " 'ResponseMetadata': {'RequestId': '37db212b-9068-4668-bdf7-810a432ffa9b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '37db212b-9068-4668-bdf7-810a432ffa9b',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2711',\n",
       "   'date': 'Fri, 03 Feb 2023 13:59:25 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d7b74",
   "metadata": {},
   "source": [
    "run this block several times until the cluster really deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7308fd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "etl.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  import psycopg2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>deleting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0d153cb688ae4965e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  deleting                                                                               \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.cm4n7audtsr1.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-0d153cb688ae4965e                                                                  \n",
       "7  2                                                                                      "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759fca1",
   "metadata": {},
   "source": [
    "Once the Redshift cluster is deleted we delete the permission '0.0.0.0/0' in the security group of the Redshift cluster that we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get the security group\n",
    "    defaultSg = ec2.SecurityGroup(id=myClusterProps['VpcSecurityGroups'][0]['VpcSecurityGroupId'])\n",
    "    \n",
    "    # Revoke the permissions of '0.0.0.0/0' in the security group\n",
    "    defaultSg.revoke_ingress(IpPermissions=defaultSg.ip_permissions)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5cbf8d",
   "metadata": {},
   "source": [
    "Finally, we detach and delete the IAM role that we created before for the Redshift cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee36465",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
